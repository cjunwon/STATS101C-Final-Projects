# STATS 101C - Regression Final Project

This file will be used to host all our code, visualizations, and text for the final report. I (Junwon) will move everything over to a document + R script before we submit, so don't worry about the formatting here!

Make sure to Slack the group before working on your code and Slack again after pushing changes!

## Introduction: context and background info. - Tiffany

o Cite any external sources\
o Can mention what variables you may believe to be associated with the response\
variable based on background information.\
o Approximately 100 words. Minimum length 80 words.

## Exploratory Data Analysis - Junwon, Han

o Explore potential relationships between the variables.\
o Must include graphics showing relationships\
o Recommended: Transformations of some variables\
o Recommended: Converting some numeric variables into categorical variables\
o Recommended: Exploration of possible interactions between variables\
o Minimum 8 data visualizations. Maximum of 20. All graphs/visualizations must be\
accompanied by a description of its significance. Descriptions must be a minimum of 20\
words, recommended something around 50 words.

```{r}
# Load packages
library(tidyverse)
library(tidymodels)
library(tidyselect)
library(recipes)
library(ggplot2)
library(forecast)

```

```{r}
# Load train and test data
train <- read_csv('train.csv')
test <- read_csv('test.csv')
```

```{r}
# Remove `name` column from train
train <- subset(train, select = -name)
```

## Preprocessing / Recipes - Bobo, Samantha

o If you use recipes or perform preprocessing of variables, you must explain the steps you\
performed and the reasoning behind them.\
o Length will vary depending on preprocessing steps. \~ 100-500 words seems reasonable.

```{r}
train <- train %>%
  mutate(across(where(is.numeric), 
                ~ ifelse(. < quantile(., 0.04, na.rm = TRUE), quantile(., 0.04, na.rm = TRUE), 
                         ifelse(. > quantile(., 0.96, na.rm = TRUE), quantile(., 0.96, na.rm = TRUE), .))))





# Skewed variable names
skewed_vars <- all_of(c('x0041e', 'x0042e', 'x0048e', 'x0050e', 'x0052e', 'x0053e', 'x0055e', 'x0056e', 'x0068e', 'x0074e', 'x0081e'))

# Variables with high percentage of zeros
high_zero_vars <- all_of(c('x0040e', 'x0041e', 'x0042e', 'x0043e', 'x0045e', 'x0046e', 'x0047e', 'x0048e', 'x0049e', 'x0050e', 'x0051e', 'x0052e', 'x0053e', 'x0054e', 'x0055e', 'x0056e'))

rf_recipe_overfit <- recipe(percent_dem ~ ., data = train) %>%
  step_rm(id) %>%
  step_zv(all_predictors()) %>%
  #step_impute_median(all_predictors(), -all_outcomes()) %>% 
  step_impute_knn(all_predictors()) %>%
  step_YeoJohnson(skewed_vars) %>%
  step_nzv(high_zero_vars, freq_cut = 65/35, unique_cut = 10) %>% 
  step_corr(all_predictors(), threshold = 0.70) %>%
  step_normalize(all_numeric_predictors(), -all_outcomes())

rf_recipe <- recipe(percent_dem ~ ., data = train) %>%
  step_rm(id) %>%
  step_zv(all_predictors()) %>%
  step_impute_knn(all_predictors()) %>%
  step_log(skewed_vars, base = exp(1), offset = 1) %>%
  step_nzv(high_zero_vars, freq_cut = 65/35, unique_cut = 10) %>%
  step_corr(all_predictors(), threshold = 0.70) %>%
  step_normalize(all_numeric_predictors(), -all_outcomes()) 
# Prep and bake the recipe


rf_recipe_prep <- prep(rf_recipe, training = train)
train_baked <- bake(rf_recipe_prep, new_data = train)
```

Here are the Data Preprocessing Steps we took: 1. Identifying Variables: o Skewed Variables: looked at the distributions of all predictors and identified highly skewed distributions o High Zero Variables: looked at the training data steps and counted how many zeros occurred on each column

2.  Removing ID `step_rm(id)` removes the `id` column from the dataset. IDs are unique to each observation and do not provide useful information for modeling.

3.  Removing Zero Variance Predictors `step_zv(all_predictors())` removes predictors that have zero variance as they don't help in making predictions and may lead to model overfitting.

4.  K-nearest Neighbors Imputation `step_impute_knn` Unlike median imputation, which fills missing values with the median of the column, k-NN imputation is more dynamic and can offer a better approximation for missing data by considering the feature similarities.

5.  Yeo-Johnson Transformation `step_YeoJohnson` Skewed variables are transformed using the Yeo-Johnson transformation to approximate a normal distribution. This makes the model more robust to outliers.

6.  Removing Near-Zero Variance Predictors `step_nrv` Variables with near-zero variance are removed. These are variables that contain values with a frequency that is either too high or too low to be informative. The parameters freq_cut and unique_cut are set to customize the filtering process.

7.  Correlation Filtering `step_corr` Correlated predictors (correlation above 0.7) are removed. High correlation among predictors can result in multicollinearity, making the model unstable.

8.  Normalization `step_normalize` All numerical variables are normalized to have zero mean and unit variance. This is particularly useful for models sensitive to the scale of input variables.

## Candidate models / Model evaluation / tuning - Everyone

o This section will discuss the various candidate models that were attempted.\
o Minimum of 5 candidate models. Maximum of 12 candidate models.\
o A brief description should accompany each candidate model.\
o Include a table listing of all candidate models attempted. Columns should include

▪ Model identifier\
▪ Type of model (e.g. linear regression, knn, random forest)\
▪ Engine\
▪ Recipe used or listing of variables in the model\
▪ Hyperparameters

o Model evaluation and tuning

▪ Discuss the evaluation and comparison of the candidate models that were\
attempted.\
▪ Students should use v-fold cross validation to measure the performance of the\
candidate models\
▪ Tuning of hyperparameters\
▪ Include a table summarizing the performance of each model. Columns should include\
• Model identifier\
• Metric score (most likely rmse)\
• SE of metric (if applicable)\
▪ Include a plot (like autoplot) comparing the performance of the different models.

```{r}
#random forest 

rf_model_random_forest<-
rand_forest() %>% 
  set_mode("regression") %>% 
  set_engine("ranger")

rf_wf_random_forest <-
  workflow() %>% 
  add_recipe(rf_recipe) %>% 
  add_model(rf_model_random_forest)

rf_fit_random_forest <-
  rf_wf_random_forest %>%
  fit(data = train)

print(rf_fit_random_forest)

```
```{r}
rf_test_res_random_forest <-
  rf_fit_random_forest %>%
  predict(train) %>% 
  cbind(train %>% select(percent_dem))
print(rf_test_res_random_forest)

rmse_value <- rmse(rf_test_res_random_forest, truth = percent_dem, estimate = .pred)
cat("Root Mean Square Error for random forest model is:", rmse_value$.estimate, "\n")
```
Since the root mean square error is low tells that the average magnitude of the errors between the predicted values from our model and the actual observed values in this dataset. A lower RMSE would indicate better model performance.  

Bagged trees via rpart model:  
```{r}
library(baguette)
library(caret)
library(rpart)
```

```{r}
# Create a Bagged Trees model
bagged_model <- bag_tree(
  tree_depth = 30,       # default Maximum tree depth
  min_n = 2,            # default Minimum number of observations in a leaf node
  cost_complexity = 0.01  # Cost complexity parameter
) %>% 
  set_engine("rpart") %>% 
  set_mode("regression")

# Train the Bagged Trees model
bagged_fit <- fit(bagged_model, percent_dem ~ ., data = train)

# Make predictions
predictions <- predict(bagged_fit, new_data = train)

rmse <- sqrt(mean((train$percent_dem - predictions$.pred)^2))
cat("An RMSE (Root Mean Squared Error) of", rmse, "means that, on average, your Bagged Trees model's predictions on the testing set are off by approximately",rmse, "percentage points when compared to the actual values. In a regression context, a lower RMSE indicates better model performance, so an RMSE of Bagged Trees model suggests that our model's predictions have some room for improvement.", "\n")


```
## Discussion of final model - Everyone

o Discuss the selection of the final model used for generating predictions.\
o Discussion of strengths and weaknesses of the model.\
o Possible improvements, including what additional data could be usef
